191004\_HW2
================
Gavin Ko
9/26/2019

# Problem 1

## A. Mr. Trashwheel Data

(Note. Library section is put in the include=false golbal setting
chunk.)

First of all, data import.

``` r
Trash_data = 
  read_excel(path = "data/Trash-Wheel-Collection-Totals-8-6-19.xlsx", 
             range = "A2:N406",
             sheet = "Mr. Trash Wheel",
             col_names = TRUE
             ) %>% 
  drop_na(Dumpster) %>% 
  janitor :: clean_names()
```

At this place, I’ve cleared all the missing or unrelated data. But, some
variable names are not clear. Therefore, I’m going to apply some
changes.

``` r
Trash_data = 
  rename(Trash_data, 
         weight = weight_tons,
         volume = volume_cubic_yards,
         )
```

Now it looks better. As requested, let’s round the sports balls.

``` r
mutate(Trash_data,
       sports_balls = round(sports_balls, digits = 0),
       sports_balls = as.integer(sports_balls)
) %>% 
pull(sports_balls)
```

    ##   [1]  7  5  6  6  7  5  3  6  6  7  6  8  6  6  6  6  5  6  6  7  6  6  6
    ##  [24]  5  6  7  8  7  4  7  3  6  6  6  7  6  6  6  7  6  6  7  6  6  7  6
    ##  [47]  5  3  8 16 14 13 16  8  5  8 11  7  6  8 22 28 19 32 24 26 36 24  9
    ##  [70] 16 22 17 13 14 21 15 13 18 16 22 32 18 21 34 19 14 22 16 25 27 18 20
    ##  [93] 17 56 32 22  6  3 17 13 12  7  8 16 23 33 27 15 21  9 13 22 17 27  8
    ## [116] 17 14 21 26  6  4 16 24 23 18 46 38 24 36 42 23 34 38 26 32 43 38 24
    ## [139] 35 26 29 31 28 34 26 38 25 16 24 15 31 22 28 32 15 28 33 11 37 22 11
    ## [162] 34  6 24 20 15 22 19 12 14 18 10  6  8  8  5  3  5  7  2  7  3  4  5
    ## [185]  8 10  5  7  5  8 10 11 14 12  8  5  9  5 14 12  8  7 18 11 22 13 21
    ## [208] 14  9  6 13 11  6  8  5  6 12  8  7 13 11 12  8  6  4  6 12 14  5  4
    ## [231]  8  3  7 10 12  1  4  2  4  3  4  3  4  2  5  1  3  2  4  2  3  4  5
    ## [254]  3  2  3  0  2  3  2  1  2  5  4  3  2  4  2  8  3  2  2  3  1  5  3
    ## [277]  1  2  7  4  5  1  7  2  3  6  1  9  0  2 14 11  6  0  4  9 16 14  8
    ## [300]  8 11  6  4  0  4  9 14  2  0  6  8  8  0  4 13 17  2 11 14  9  0  6
    ## [323]  6  3 11 14  4  8  1  4  8 14  9  4  4 14 22  6  9 10  8 17  8 16

Now the data is good to go\!

## B. Precipitation Data

Let’s read in the data for 2017 & 2018 first.

``` r
Precipitation_2017 = 
  read_excel(path = "data/Trash-Wheel-Collection-Totals-8-6-19.xlsx",
             range = "A2:B14",
             sheet = "2017 Precipitation",
             col_names = TRUE) %>% 
  janitor::clean_names() %>% 
  drop_na(total)

Precipitation_2018 = 
  read_excel(path = "data/Trash-Wheel-Collection-Totals-8-6-19.xlsx",
             range = "A2:B14",
             sheet = "2018 Precipitation",
             col_names = TRUE) %>% 
  janitor::clean_names() %>% 
  drop_na(total)
```

Before the combination take place, we need to add the year variable.

``` r
Precipitation_2017 = 
  mutate(Precipitation_2017,
         year = 2017)

Precipitation_2018 = 
  mutate(Precipitation_2018,
         year = 2018)
```

Now, let’s try to combine the data.

``` r
Precipitation_merged = bind_rows(Precipitation_2017, Precipitation_2018) 
```

This doesn’t look really tidy, so let me also change the order.

``` r
Precipitation_merged = 
  select(Precipitation_merged, year, everything()) %>% 
  mutate(
  month = as.numeric(month),
  month = month.name[month],)
```

For data summary, I’m going to talk about Mr. Trash Wheel first. Key
variables are the recorded date(`date`), sediment weight(`weight`),
volume(`volume`) and homes powered by Mr. Trash Wheel(`homes_powered`).
After removing missing data, Mr. Trash Wheel dataset has collected
record from n = 344 dumpsters, with 14 columns of variables. Among these
observations, the average weight of waste was 3.26 tons, with median at
3.265 tons. Maximum weight record happened in 2015-05-17, which recorded
a historical 5.62 tons of waste. In volume scale, the average volume of
waste was 15.54 qubic yrads, with median at 15 qubic yards. Maximum
volume record happened in 2014-08-13, which recorded a historical 20
quibic yards of waste. During the data collection period, Mr. Trash
Wheel has contributed in total 1122.45 tons, 5347 qubic yards of waste,
and powered 15075 families. Thanks Mr. Trash Wheel\!

Secondly, I’m going to talk about Precipitation data.

After removing missing data, Precipitation dataset has collected record
n = 24 months of data, with 3 columns of variables. Among these
observations, the mean sediment depth was 4.3 inches, with median at
4.215 inches. Total amount of collected sediment depth during this
period was 103.26 inches. Maximum amount of sediment was recorded on
September, 2018 with 10.47 inches of precipitation.

Specific to precipitation in 2018, the total sediments was 70.33 inches.

Specific to sports balls, the median number of them in 2017 was 8.

# Problem 2

First, read the files.

``` r
Pols_month_data = read.csv("data/pols-month.csv") %>% 
  janitor::clean_names()

Unemployment_data = read.csv("data/unemployment.csv") %>% 
  janitor::clean_names()

Snp_data = read.csv("data/snp.csv") %>% 
  janitor::clean_names()
```

Of course it is not clean enough. Let’s deal with pols-month first.

``` r
Pols_month_data = 
  mutate(Pols_month_data,
         mon = as.character(mon)) %>% 
  separate(mon, into = c("year","month","day"), sep = "-") %>%
  mutate(month = month.name[as.numeric(month)],
         president = prez_gop - prez_dem,
         president = factor(president, labels = c("dem","gop","gop"))) %>%
  select(year, month, president, everything(), -day, -prez_dem, -prez_gop)
```

Secondly, time for snp.

``` r
Snp_data = 
  separate(Snp_data, date, into = c("month", "day", "year"), sep = "/") %>%
  select(year, month, snp_close = close, -day) %>% 
  mutate(month = as.numeric(month)) %>% 
  arrange(year, month) %>% 
  mutate(month = month.name[month])
```

Lastly, unemployment.

``` r
Unemployment_data = 
  pivot_longer(Unemployment_data,
               jan:dec,
               names_to = "month",
               values_to = "unemployment_rate"
               ) %>% 
  mutate(month = month.name[factor(month)],
         year = as.character(year))
```

Last step is to join the data.

``` r
Complete_data = 
  left_join(Pols_month_data, Snp_data, by = c("year","month") ) %>% 
  left_join(Unemployment_data, by = c("year","month")) 
```

First dataset `pols` contains political data at that time: the party of
current President (`president`), respective numbers of
Governors(`gov_gop, gov_dem`), Senators(`sen_gop, sen_dem`), and
Representatives(`rep_gov, rep_dem`). The second dataset `snp` contains
the S\&P 500 Index at the designated closing month(`snp_close`), which
gives a sense of economic status at that time. The last dataset
`unemployment` contains unemployment rate in US at that time. The merged
dataset contains 822 months of data with 11 variables recorded. Years
ranged from Jan,1947 to Jun, 2015. The NA status in `snp_close` and
`unemployment_rate` is owing to the original data collection period.
While snp data started from 1950, unemployment rate record started from
1948.

# Problem 3

First of all, read the data again. During the process, I’ve also done
the lowercases and ethnicity factor adjustment. After that, I’ve removed
the duplicates.

``` r
Pop_baby = read_csv("data/Popular_Baby_Names.csv", col_types = "icccii") %>% 
  janitor::clean_names() %>% 
  mutate(
    gender = factor(str_to_lower(gender)),
    ethnicity = factor(str_to_lower(ethnicity)),
    ethnicity = recode(ethnicity, "asian and paci" = "asian and pacific islander",
                                  "black non hisp" = "black non hispanic",
                                  "white non hisp" = "white non hispanic"),
    childs_first_name = str_to_lower(childs_first_name)) %>% 
  distinct(year_of_birth, gender, ethnicity, childs_first_name, count, rank)
```

Now the data is ready to go\!

Dealing with Olivia:

``` r
Olivia_table = 
  filter(Pop_baby, childs_first_name == "olivia" & gender == "female") %>% 
  select(year_of_birth, ethnicity, rank) %>% 
  pivot_wider(
    names_from = year_of_birth,
    values_from = rank)
Olivia_table
```

    ## # A tibble: 4 x 7
    ##   ethnicity                  `2016` `2015` `2014` `2013` `2012` `2011`
    ##   <fct>                       <int>  <int>  <int>  <int>  <int>  <int>
    ## 1 asian and pacific islander      1      1      1      3      3      4
    ## 2 black non hispanic              8      4      8      6      8     10
    ## 3 hispanic                       13     16     16     22     22     18
    ## 4 white non hispanic              1      1      1      1      4      2

Favorite male children names:

``` r
Male_children_table =
  filter(Pop_baby, rank == 1 & gender == "male") %>% 
  select(year_of_birth, ethnicity, childs_first_name) %>% 
  pivot_wider(
    names_from = year_of_birth,
    values_from = childs_first_name)
Male_children_table
```

    ## # A tibble: 4 x 7
    ##   ethnicity                  `2016` `2015` `2014` `2013` `2012` `2011` 
    ##   <fct>                      <chr>  <chr>  <chr>  <chr>  <chr>  <chr>  
    ## 1 asian and pacific islander ethan  jayden jayden jayden ryan   ethan  
    ## 2 black non hispanic         noah   noah   ethan  ethan  jayden jayden 
    ## 3 hispanic                   liam   liam   liam   jayden jayden jayden 
    ## 4 white non hispanic         joseph david  joseph david  joseph michael

Lastly, produce the scatter plot.

``` r
  filter(Pop_baby, year_of_birth == 2016 & gender == "male" & ethnicity == "white non hispanic") %>% 
  ggplot(aes(x = rank, y = count)) + geom_point() +
  ggtitle("2016 White Male Baby Names Popularity")
```

![](p8105_hw2_wk2343_files/figure-gfm/filtered%20data-1.png)<!-- -->
